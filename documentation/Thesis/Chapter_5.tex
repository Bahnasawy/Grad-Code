\chapter{Implementation}

\section{Database}
The database is accessed through a serverless function running a library called PostGraphile. The library introspects the database and creates a graphQL API to communicate with the database.

\subsection{Code}
\begin{verbatim}
const express = require("serverless-express/express");
const { postgraphile } = require("postgraphile");
var cors = require("cors");

const { SCHEMA, PG_DEFAULT_ROLE, POSTGRES_CONNECTION } = process.env;

const app = express();
app.use(cors());
app.use(
        postgraphile("postgres://postgres:@localhost:5432/grad", "public", {
                dynamicJson: true,
                graphqlRoute: "/",
                extendedErrors: ["hint", "detail", "errcode"],
                legacyRelations: "omit",
                pgDefaultRole: PG_DEFAULT_ROLE,
                subscriptions: true,
                setofFunctionsContainNulls: false,
                ignoreRBAC: false,
                appendPlugins: [
                        require("@graphile-contrib/pg-simplify-inflector"),
                        require("postgraphile-plugin-connection-filter"),
                        require("postgraphile-plugin-many-create-update-delete").default,
                ],
                retryOnInitFail: true,
                graphileBuildOptions: {
                        connectionFilterRelations: true,
                },
                graphiql: true,
                graphiqlRoute: "/graphiql",
        })
);

app.listen(8000, () => console.log(`Server running on port 8000`));
\end{verbatim}

\section{Server / Parser}
The parser server is meant to parse the text according to the selected grammar and returns the result in JSON format.

\subsection{Problems}
The system uses the nltk tokenizer, which has an extremely high success rate, but with large enough texts defects start to show and those errors may cause the parser have false results, positive and/or negative.

\subsection{Code}
\begin{verbatim}
    tokens = nltk.tokenize.word_tokenize(text)

    sentences = []
    temp = []
    for token in tokens:
        if token == "." or token == "?" or token == "!":
            sentences.append(temp)
            temp = []
        else:
            temp.append(token)

    pos = nltk.pos_tag_sents(sentences)


    # Parsing
    results = []
    for feature in features:
        temp = []
        for sent in pos:
            temp.append(nltk.RegexpParser(feature["grammar"]).parse(sent))
        results.append(temp)


    # Clean Up and Separation of features results
    featuresTags = {}
    for idx, feature in enumerate(features):
        sents = []
        for sent in results[idx]:
            temp = []
            for tag in sent:
                if type(tag) is tree.Tree:
                    leafArr = []
                    for leaf in tag.leaves():
                        leafArr.append(leaf[0])
                    temp.append([leafArr ,tag.label(), True])
                else:
                    temp.append([[tag[0]],tag[1], False])
            sents.append(temp)
        featuresTags[features[idx]["name"]] = sents
\end{verbatim}